{"cells":[{"cell_type":"markdown","metadata":{"id":"sh6KdaoQIhtR"},"source":["# **Elaborazione di Immagini Mediche**\n","## Vessel Wall Segmentation Challenge - A.A. 2021/22 \n","\n","### Script di Preprocessing\n","\n","Rigazio Sofia, Roccaro Lucia, Romano Anastasio, Ruzzante Elena"]},{"cell_type":"markdown","metadata":{"id":"vBzvaDj3Io8B"},"source":["Collegamento a Google Drive e installazione delle librerie necessarie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZD1JvhVfQnI"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install tensorflow==2.1.0\n","!pip install keras==2.3.1\n","!pip install plotly==5.3.1"]},{"cell_type":"markdown","metadata":{"id":"j0DGsHkaI3jT"},"source":["\n","\n","Importazione delle librerie necessarie\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpJAl9SpUB8D"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import plotly.express as px\n","import pickle\n","import math\n","\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","from skimage.io import imread\n","from skimage.transform import resize\n","from skimage.segmentation import mark_boundaries\n","\n","from keras.utils.np_utils import to_categorical\n","\n","from skimage.measure import regionprops\n","import tensorflow as tf\n","import json"]},{"cell_type":"markdown","metadata":{"id":"xe8q2nilVO0g"},"source":["Definizione delle directory e dei path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8qZACUQAsjm"},"outputs":[],"source":["current_dir = '/content/drive/MyDrive/Colab Notebooks/EIM/VesselWallSegmentationChallenge'\n","dataset_name = '3D_dataset'\n","\n","TRAIN_path = os.path.join(current_dir,dataset_name,'TRAIN')\n","VAL_path = os.path.join(current_dir,dataset_name,'VALIDATION')\n","\n","JSON_path = os.path.join(current_dir,'PICKLE_and_JSON')\n","PICKLE_ICA_path = os.path.join(JSON_path,'ICA')\n","PICKLE_ECA_path = os.path.join(JSON_path,'ECA')\n","\n","carotid_types = ['ICA','ECA']\n","arts = ['ICAL','ECAL','ICAR','ECAR']\n","\n","# Creazione della cartelle che conterranno file utili da passare tra gli script\n","for carotid_type in carotid_types:\n","  try:\n","    os.mkdir(eval(f'PICKLE_{carotid_type}_path'))\n","  except:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"CkBPd04ucaw3"},"source":["Estrazione della lista di volumi di Training e Validation set e load dei dizionari contenenti le informazioni sulle slice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IV4-vMZeVYZe"},"outputs":[],"source":["train_folders_ICA = []\n","train_folders_ECA = []\n","val_folders_ICA = []\n","val_folders_ECA = []\n","for arti in arts:\n","  # Training set\n","  for casei in os.listdir(TRAIN_path):\n","    cpath = os.path.join(TRAIN_path, casei, arti)\n","    if arti[0:3] == carotid_types[0]: # ICA\n","      train_folders_ICA.append(cpath)\n","    else: # ECA\n","      train_folders_ECA.append(cpath)\n","\n","  # Validation set\n","  for casei in os.listdir(VAL_path):\n","    cpath = os.path.join(VAL_path, casei, arti)\n","    if arti[0:3] == carotid_types[0]: # ICA\n","      val_folders_ICA.append(cpath)\n","    else: # ECA\n","      val_folders_ECA.append(cpath)\n","\n","# load dei dizionari contenenti le informazioni sulle immagini\n","with open(os.path.join(JSON_path,'labels_TRAIN.json'),\"r\") as f:\n","  labels_TRAIN = json.load(f)\n","  f.close\n","with open(os.path.join(JSON_path,'labels_VAL.json'),\"r\") as f:\n","  labels_VAL = json.load(f)\n","  f.close"]},{"cell_type":"markdown","metadata":{"id":"I6iKIY8EJN4G"},"source":["Settaggio dei parametri "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyOM6TBSo-66"},"outputs":[],"source":["# Definiamo i parametri\n","typical_shape = labels_VAL[list(labels_VAL.keys())[0]]['original_shape']\n","IMG_WIDTH = typical_shape[1] # la larghezza sono le colonne\n","IMG_HEIGHT = typical_shape[0] # l'altezza sono le righe\n","NUM_CLASSES = 3 # vogliamo segmentare tre classi per ogni rete: lume, wall e background\n","IMG_CHANNELS = 1 # Le immagini fornite sono grayscale\n","# il numero di slice è variabile -> non lo definiamo\n","print(f'Dimensioni originali tipiche: {typical_shape}')"]},{"cell_type":"markdown","metadata":{"id":"XEZ_VdZPMrrX"},"source":["Visualizzazione del contorno dell'oggetto su una slice dell'immagine originale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INICXVFjvpvU"},"outputs":[],"source":["# Troviamo la prima cartella esistente dalla lista di cartelle ICA\n","chosen_folder = None \n","i = 0\n","while chosen_folder == None:\n","  try:\n","    volume = imread(os.path.join(train_folders_ICA[i], 'image.tiff'))\n","    chosen_folder = train_folders_ICA[i]\n","  except:\n","    pass\n","  i = i+1\n","lumen_mask = imread(os.path.join(chosen_folder, 'lumen_mask.tiff'))\n","wall_mask = imread(os.path.join(chosen_folder, 'wall_mask.tiff'))\n","\n","# Estrazione della prima slice\n","slice_chosen = 1\n","slice_1 = volume[slice_chosen-1,:,:]\n","wall_mask_1 = wall_mask[slice_chosen-1,:,:]\n","lumen_mask_1 = lumen_mask[slice_chosen-1,:,:]\n","\n","# Plot a video dell'immagine originale e della corrispondente segmentazione manuale\n","fig = plt.figure(figsize=(25,15))\n","ax1 = fig.add_subplot(3,1,1)\n","ax1.imshow(slice_1,cmap=plt.cm.gray), ax1.set_title('Original image')\n","\n","ax2 = fig.add_subplot(3,1,2)\n","ax2.imshow(wall_mask_1-lumen_mask_1,cmap=plt.cm.gray), ax2.set_title('Manual segmentation')    \n","\n","ax3 = fig.add_subplot(3,1,3)\n","ax3.imshow(mark_boundaries(slice_1,(wall_mask_1-lumen_mask_1).astype(np.uint8),color=(1,0,0))), ax3.set_title('Original image + Manual segmentation contour') \n","# NOTA: per utilizzare la funzione mark_boundaries è necessario convertire la maschera in formato int "]},{"cell_type":"markdown","metadata":{"id":"68-Y3xdwq5yr"},"source":["Creazione delle matrici contenenti immagini e maschere"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2haSUvLqz4U"},"outputs":[],"source":["def flip_and_crop(image,mask,side):\n","# flip left-right se è lato sinistro (a destra nell'immagine)  \n","  if side == 'L':\n","    image = np.fliplr(image)\n","    mask = np.fliplr(mask)\n","\n","  # consideriamo solo la metà sinistra dell'immagine (che contiene ICAL/ECAL flippate o ICAR/ECAR)\n","  half_width = int(image.shape[1]/2)\n","  image = image[:,0:half_width]\n","  mask = mask[:,0:half_width,:]\n","  \n","  # controllo sulle dimensioni delle immagini\n","  if image.shape != (IMG_HEIGHT,int(IMG_WIDTH/2)): #(100,360)\n","    # effettuiamo un resize with pad per mantenere l'aspect ratio delle immagini \n","    # e delle maschere\n","    image = np.expand_dims(image,axis = 2)\n","    image = np.squeeze(tf.image.resize_with_pad(image,IMG_HEIGHT,int(IMG_WIDTH/2), antialias=True).numpy())\n","    mask = tf.image.resize_with_pad(mask,IMG_HEIGHT,int(IMG_WIDTH/2), antialias=True).numpy() \n","    # reimpostiamo i valori dei pixel coinvolti nel resize a 0 e 1: i pixel ai \n","    # bordi delle segmentazioni potrebbero essersi sfumati\n","    soglia = 0.5\n","    mask[mask < soglia] = 0.0\n","    mask[mask >= soglia] = 1.0\n","\n","    # Spostiamo le colonne aggiunte con lo zero padding a sinistra dell'immagine\n","    # con lo zero padding vengono inserite 80 colonne nere per lato\n","    to_shift = 80  \n","    image = np.roll(image, to_shift, axis = 1)\n","    mask = np.roll(mask, to_shift, axis = 1)\n","\n","  return image, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXog-RHQQn3V"},"outputs":[],"source":["def create_matrix (list_folders,n_images,labels):\n","  # inizializzazioni\n","  X = np.zeros((n_images,IMG_HEIGHT,int(IMG_WIDTH/2)),dtype = np.uint8)\n","  Y = np.zeros((n_images,IMG_HEIGHT,int(IMG_WIDTH/2),NUM_CLASSES),dtype = np.float32)\n","  names = [] # lista che conterrà i nomi delle immagini originali\n","\n","  slice_counter = 0 # contatore del numero di slice\n","  for v_subj in tqdm(list_folders, total = len(list_folders)):\n","    subject_ID = v_subj.split('/')[-2]\n","    arti = v_subj.split('/')[-1]\n","    if os.path.exists(v_subj) == True: # se la cartella esiste (ovvero se abbiamo le segmentazioni)\n","      # Lettura dell'immagine e delle maschere\n","      volume = imread(os.path.join(v_subj, 'image.tiff'))\n","      wall_mask = imread(os.path.join(v_subj, 'wall_mask.tiff'))\n","      lumen_mask = imread(os.path.join(v_subj, 'lumen_mask.tiff'))\n","\n","      # consideriamo una slice alla volta\n","      for i in range(volume.shape[0]):\n","        slice_counter = slice_counter + 1 # incrementiamo il contatore del numero di slice\n","        \n","        # Conversione della maschera in dato categorico\n","        mask_cat = to_categorical(wall_mask[i]+lumen_mask[i], num_classes=NUM_CLASSES, dtype='float32')\n","        # mask_cat[:,:,0] = background, mask_cat[:,:,1] = wall, mask_cat[:,:,2] = lumen\n","        \n","        # Preprocessing\n","        arti = v_subj.split(\"/\")[-1] # [ICAL, ICAR, ECAL, ECAR]\n","        [volume_slice,mask_slice] = flip_and_crop(volume[i],mask_cat,arti[-1])\n","        # creiamo un'unica maschera sommando le maschere di lume e wall, in questo modo avremo:\n","        # background con valore 0, parete con valore 1, lume con valore 2\n","\n","        # inserimento di immagine e maschera nella matrice\n","        X[slice_counter-1] = volume_slice\n","        Y[slice_counter-1] = mask_slice\n","\n","        names.append(arti+'_'+labels[subject_ID][arti+'_original']['name'][i])\n","\n","  return X, Y, names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I3FO8FSVRbmj"},"outputs":[],"source":["# numero di slice disponibili\n","for carotid_type in carotid_types:\n","  # Training set\n","  slice_list = [labels_TRAIN[casei][f\"{carotid_type}L_original\"][\"number\"] for casei in os.listdir(TRAIN_path)]\n","  n_slices_L_train = sum([len(slice_list[i]) for i in range(len(slice_list))])\n","  slice_list = [labels_TRAIN[casei][f\"{carotid_type}R_original\"][\"number\"] for casei in os.listdir(TRAIN_path)]\n","  n_slices_R_train = sum([len(slice_list[i]) for i in range(len(slice_list))])\n","  # Validation set\n","  slice_list = [labels_VAL[casei][f\"{carotid_type}L_original\"][\"number\"] for casei in os.listdir(VAL_path)]\n","  n_slices_L_val = sum([len(slice_list[i]) for i in range(len(slice_list))])\n","  slice_list = [labels_VAL[casei][f\"{carotid_type}R_original\"][\"number\"] for casei in os.listdir(VAL_path)]\n","  n_slices_R_val = sum([len(slice_list[i]) for i in range(len(slice_list))])\n","  \n","  if carotid_type == 'ICA':\n","    n_images_train_ICA = n_slices_L_train + n_slices_R_train\n","    n_images_val_ICA = n_slices_L_val + n_slices_R_val\n","  else:\n","    n_images_train_ECA = n_slices_L_train + n_slices_R_train\n","    n_images_val_ECA = n_slices_L_val + n_slices_R_val\n","\n","# creazione delle matrici\n","# Training Set\n","print('Reading images - Training set')\n","print('ICA')\n","[X_train_ICA,Y_train_ICA,names_train_ICA] = create_matrix(train_folders_ICA,n_images_train_ICA,labels_TRAIN)\n","print('ECA')\n","[X_train_ECA,Y_train_ECA,names_train_ECA] = create_matrix(train_folders_ECA,n_images_train_ECA,labels_TRAIN)\n","\n","# Validation Set\n","print('\\nReading images - Validation set')\n","print('ICA')\n","[X_val_ICA,Y_val_ICA,names_val_ICA] = create_matrix(val_folders_ICA,n_images_val_ICA,labels_VAL)\n","print('ECA')\n","[X_val_ECA,Y_val_ECA,names_val_ECA] = create_matrix(val_folders_ECA,n_images_val_ECA,labels_VAL)"]},{"cell_type":"markdown","metadata":{"id":"1g6K6Lw1FVPF"},"source":["Identificazione delle soglie per la rimozione delle biforcazioni"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcK_nrydFVAF"},"outputs":[],"source":["# numero totale di slice appartenenti al Training set\n","total_slices = X_train_ICA.shape[0] + X_train_ECA.shape[0]\n","\n","# inizializziamo le proprietà \n","# roundness come vettori di 1 e area come vettore di 0\n","roundness_wall = np.ones((total_slices,1),dtype = np.float32)\n","roundness_lumen = np.ones((total_slices,1),dtype = np.float32)\n","area_wall = np.zeros((total_slices,1),dtype = np.uint32)\n","area_lumen = np.zeros((total_slices,1),dtype = np.uint32)\n","\n","for n_slice in range(total_slices):\n","  if n_slice < X_train_ICA.shape[0]:\n","    wall_mask = Y_train_ICA[n_slice,:,:,1] + Y_train_ICA[n_slice,:,:,2]\n","    lumen_mask = Y_train_ICA[n_slice,:,:,2]\n","  else:\n","    wall_mask = Y_train_ECA[n_slice-X_train_ICA.shape[0],:,:,1] + Y_train_ECA[n_slice-X_train_ICA.shape[0],:,:,2]\n","    lumen_mask = Y_train_ECA[n_slice-X_train_ICA.shape[0],:,:,2]\n","\n","  # lumen\n","  properties = regionprops(lumen_mask.astype(np.uint8), cache=False)\n","  # se le maschere sono nere, la funzione regionprops non calcola le proprietà\n","  if len(properties): \n","    if properties[0].major_axis_length == 0:\n","      # se ci sono maschere con lume composto da un solo punto (l'asse maggiore\n","      # in questo caso ha lunghezza pari a 0) si tratta di errori: impostiamo \n","      # quindi le roundness pari a 0 in modo da eliminare le maschere\n","      roundness_lumen[n_slice] = 0\n","      roundness_wall[n_slice] = 0\n","    else:\n","      area_lumen[n_slice] = lumen_mask.sum()\n","      roundness_lumen[n_slice] = 4*area_lumen[n_slice]/(math.pi*properties[0].major_axis_length**2)\n","      # wall\n","      area_wall[n_slice] = wall_mask.sum()\n","      properties = regionprops(wall_mask.astype(np.uint8), cache=False)\n","      roundness_wall[n_slice] = 4*area_wall[n_slice]/(math.pi*properties[0].major_axis_length**2)\n","\n","# visualizzaizone degli istogrammi\n","fig = plt.figure(figsize=(20, 5))\n","ax1 = plt.subplot(1, 3, 1)\n","ax1.hist(roundness_lumen, bins=100, range=(0,1))\n","ax1.set_title('Roundness lumen')\n","\n","ax2 = plt.subplot(1, 3, 2)\n","ax2.hist(roundness_wall, bins=100, range=(0,1))\n","ax2.set_title('Roundness wall')\n","\n","ax3 = plt.subplot(1, 3, 3)\n","ax3.hist(area_lumen, bins=100)\n","ax3.set_title('Area lumen')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"_6drgTEQaGau"},"source":["Funzione per la rimozione automatica delle slice che contengono biforcazioni"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkAGZov_4rfc"},"outputs":[],"source":["def rimozione_biforcazioni(X,Y,names):\n","  # eliminazione automatica delle biforcazioni\n","\n","  removed_slices = [] # nomi delle slice rimosse\n","  # matrici di immagini e maschere rimosse, utili per la visualizzazione\n","  X_bif = np.zeros((1,IMG_HEIGHT,int(IMG_WIDTH/2)),dtype = np.uint8)\n","  Y_bif = np.zeros((1,IMG_HEIGHT,int(IMG_WIDTH/2),NUM_CLASSES),dtype = np.float32)\n","\n","  n_slice = 0\n","  while n_slice < Y.shape[0]:\n","    wall_mask = Y[n_slice,:,:,1] + Y[n_slice,:,:,2]\n","    lumen_mask = Y[n_slice,:,:,2]\n","\n","    # lumen\n","    properties = regionprops(lumen_mask.astype(np.uint8), cache=False)\n","    # se le maschere sono nere, la funzione regionprops non calcola le proprietà\n","    if len(properties): \n","      if properties[0].major_axis_length == 0:\n","        # se ci sono maschere con lume composto da un solo punto (l'asse \n","        # maggiore in questo caso ha lunghezza pari a 0) si tratta di errori \n","        # nelle segmentazioni manuali: impostiamo quindi le roundness pari a 0 e\n","        # l'area maggiore della soglia in modo da eliminare le maschere\n","        roundness_lumen = 0\n","        roundness_wall = 0\n","        area_lumen = soglia_area_lumen + 1\n","      else:\n","        area_lumen = lumen_mask.sum()\n","        roundness_lumen = 4*area_lumen/(math.pi*properties[0].major_axis_length**2)\n","        # wall\n","        area_wall = wall_mask.sum()\n","        properties = regionprops(wall_mask.astype(np.uint8), cache=False)\n","        roundness_wall = 4*area_wall/(math.pi*properties[0].major_axis_length**2)\n","    else:\n","      # se le maschere sono nere (quelle introdotte per il training della rete), \n","      # impostiamo dei valori delle proprietà in modo che le slice non vengano \n","      # eliminate\n","      roundness_lumen = 1\n","      roundness_wall = 1\n","      area_lumen = 0\n","\n","    # rimozione della maschera e della rispettiva immagine dalle matrici:\n","    # effettuiamo il controllo sia su wall che su lumen. se solo wall o solo \n","    # lumen ha forma allungata, allora non ci troviamo in corrispondenza di una \n","    # biforcazione. la forma non circolare potrebbe essere dovuta ad esempio \n","    # alla presenza di una placca\n","    if roundness_wall < soglia_wall and roundness_lumen < soglia_lumen and area_lumen > soglia_area_lumen:\n","      # concateniamo la slice rimossa alle matrici di visualizzazione\n","      X_bif = np.vstack((X_bif,np.expand_dims(X[n_slice],axis=0)))\n","      Y_bif = np.vstack((Y_bif,np.expand_dims(Y[n_slice],axis=0)))\n","      # concateniamo il nome della slice rimossa alla lista di nomi\n","      removed_slices.append(names.pop(n_slice))\n","      # rimuoviamo la slice dalle matrici X e Y\n","      X = np.delete(X,n_slice,axis=0)\n","      Y = np.delete(Y,n_slice,axis=0)\n","      \n","    else:\n","      n_slice = n_slice+1\n","\n","  # eliminiamo la prima slice dalle matrici ottenute con vstack (contiene zeri)   \n","  X_bif = np.delete(X_bif,0,axis=0)\n","  Y_bif = np.delete(Y_bif,0,axis=0)\n","\n","  return X, Y, names, removed_slices, X_bif, Y_bif"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57-9ytPATtCJ"},"outputs":[],"source":["# definizione delle soglie in base agli istogrammi\n","soglia_wall = 0.7\n","soglia_lumen = 0.65\n","soglia_area_lumen = 245\n","\n","# richiamo della funzione per eliminare le biforcazioni\n","# ICA\n","X_train_ICA,Y_train_ICA,names_train_ICA,removed_slices_train_ICA,X_bif_train_ICA,Y_bif_train_ICA = rimozione_biforcazioni(X_train_ICA,Y_train_ICA,names_train_ICA)\n","X_val_ICA,Y_val_ICA,names_val_ICA,removed_slices_val_ICA,X_bif_val_ICA,Y_bif_val_ICA = rimozione_biforcazioni(X_val_ICA,Y_val_ICA,names_val_ICA)\n","# ECA\n","X_train_ECA,Y_train_ECA,names_train_ECA,removed_slices_train_ECA,X_bif_train_ECA,Y_bif_train_ECA = rimozione_biforcazioni(X_train_ECA,Y_train_ECA,names_train_ECA)\n","X_val_ECA,Y_val_ECA,names_val_ECA,removed_slices_val_ECA,X_bif_val_ECA,Y_bif_val_ECA = rimozione_biforcazioni(X_val_ECA,Y_val_ECA,names_val_ECA)\n","\n","print('Numero di slice identificate come biforcazioni e rimosse:')\n","print(f'ICA\\tTraining set: {len(removed_slices_train_ICA)}')\n","print(f'\\tValidation set: {len(removed_slices_val_ICA)}')\n","print(f'ECA\\tTraining set: {len(removed_slices_train_ECA)}')\n","print(f'\\tValidation set: {len(removed_slices_val_ECA)}')\n","\n","# aggiornamento del numero di slice rimanenti\n","n_images_train_ICA = X_train_ICA.shape[0]\n","n_images_val_ICA = X_val_ICA.shape[0]\n","n_images_train_ECA = X_train_ECA.shape[0]\n","n_images_val_ECA = X_val_ECA.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"mhQJ4sZyeij9"},"source":["Visualizzazione degli istogrammi con le soglie scelte evidenziate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3WAsTwreibH"},"outputs":[],"source":["fig = plt.figure(figsize=(20, 5))\n","ax1 = plt.subplot(1, 3, 1)\n","ax1.hist(roundness_lumen, bins=100, range=(0,1))\n","ax1.axvline(soglia_lumen, color='r', linestyle='dashed', linewidth=1)\n","ax1.set_title('Roundness lumen')\n","\n","ax2 = plt.subplot(1, 3, 2)\n","ax2.hist(roundness_wall, bins=100, range=(0,1))\n","ax2.axvline(soglia_wall, color='r', linestyle='dashed', linewidth=1)\n","ax2.set_title('Roundness wall')\n","\n","ax3 = plt.subplot(1, 3, 3)\n","ax3.hist(area_lumen, bins=100)\n","ax3.axvline(soglia_area_lumen, color='r', linestyle='dashed', linewidth=1)\n","ax3.set_title('Area lumen')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"f3nvmS4fDA6d"},"source":["Visualizzazione delle slice rimosse dalle matrici ICA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2giOHWzdDDPd"},"outputs":[],"source":["# Training set\n","Y_vis = np.zeros((len(removed_slices_train_ICA),IMG_HEIGHT, int(IMG_WIDTH/2), 3), dtype = np.float32)\n","for i in range(len(removed_slices_train_ICA)):\n","  Y_vis[i] = mark_boundaries(X_bif_train_ICA[i],Y_bif_train_ICA[i,:,:,1].astype(np.uint8))\n","fig = px.imshow(Y_vis, animation_frame=0, labels=dict(animation_frame=\"slice\"))\n","for i, frame in enumerate(fig.frames):\n","  carotide = removed_slices_train_ICA[i].split('_')[0]\n","  slice_name = removed_slices_train_ICA[i].split('_')[1]\n","  frame.layout.title = f'Carotide: {carotide} - Nome slice: {slice_name}'\n","fig.show()\n","\n","# Validation set\n","Y_vis = np.zeros((len(removed_slices_val_ICA),IMG_HEIGHT, int(IMG_WIDTH/2), 3), dtype = np.float32)\n","for i in range(len(removed_slices_val_ICA)):\n","  Y_vis[i] = mark_boundaries(X_bif_val_ICA[i],Y_bif_val_ICA[i,:,:,1].astype(np.uint8))\n","fig = px.imshow(Y_vis, animation_frame=0, labels=dict(animation_frame=\"slice\"))\n","for i, frame in enumerate(fig.frames):\n","  carotide = removed_slices_val_ICA[i].split('_')[0]\n","  slice_name = removed_slices_val_ICA[i].split('_')[1]\n","  frame.layout.title = f'Carotide: {carotide} - Nome slice: {slice_name}'\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"x3T8_y7K8wBz"},"source":["Rimozione dai dizionari delle slice rimosse in questa fase e salvataggio dei dizionari aggiornati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzdNtXm68v0R"},"outputs":[],"source":["for carotid_type in carotid_types:\n","  # Training set\n","  for rem_slice in eval(f'removed_slices_train_{carotid_type}'):\n","    arti = rem_slice.split('_')[0]\n","    name = rem_slice.split('_')[1]\n","    for v_subj in labels_TRAIN:\n","      if name in labels_TRAIN[v_subj][arti]['name']:\n","        index = labels_TRAIN[v_subj][arti]['name'].index(name)\n","        labels_TRAIN[v_subj][arti]['name'].pop(index)\n","        labels_TRAIN[v_subj][arti]['number'].pop(index)\n","\n","  # Validation set\n","  for rem_slice in eval(f'removed_slices_val_{carotid_type}'):\n","    arti = rem_slice.split('_')[0]\n","    name = rem_slice.split('_')[1]\n","    for v_subj in labels_VAL:\n","      if name in labels_VAL[v_subj][arti]['name']:\n","        index = labels_VAL[v_subj][arti]['name'].index(name)\n","        labels_VAL[v_subj][arti]['name'].pop(index)\n","        labels_VAL[v_subj][arti]['number'].pop(index)\n","\n","# salvataggio dei dizionai aggiornati\n","with open(os.path.join(JSON_path,'labels_TRAIN.json'),\"w\") as f:\n","  json.dump(labels_TRAIN,f,indent = 4)\n","  f.close\n","with open(os.path.join(JSON_path,'labels_VAL.json'),\"w\") as f:\n","  json.dump(labels_VAL,f,indent = 4)\n","  f.close"]},{"cell_type":"markdown","metadata":{"id":"eMMlEsNXD3LQ"},"source":["Estrazione della ROI - ICA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2DQoUQs1Dpzq"},"outputs":[],"source":["# cerchiamo una ROI nelle immagini, identificata come il minimo rettangolo \n","# contenente tutte le segmentazioni manuali delle immagini del Training set\n","Y_sum = np.sum(Y_train_ICA[:,:,:,1]+Y_train_ICA[:,:,:,2],axis = 0)\n","Y_sum[Y_sum>0] = 1\n","fig = px.imshow(Y_sum)\n","fig.show()\n","\n","limits = np.where(Y_sum>0)\n","row_ICA = [limits[0].min(),limits[0].max()]\n","col_ICA = [limits[1].min(),limits[1].max()] # larghezza 105\n","\n","# Per essere sicuri di comprendere anche tutti i casi del Test e Validation set,\n","# aumentiamo le dimensioni della ROI ottenuta del 10% per lato\n","aumento_dim = 0.1\n","row_ICA[0] = int(min(abs(row_ICA[0]-round(aumento_dim*(row_ICA[1]-row_ICA[0]))),0))\n","row_ICA[1] = int(min(IMG_HEIGHT-1, row_ICA[1]+round(aumento_dim*(row_ICA[1]-row_ICA[0]))))\n","\n","col_ICA[0] = col_ICA[0] - round(aumento_dim*(col_ICA[1]-col_ICA[0]))\n","col_ICA[1] = int(min(IMG_WIDTH/2-1, col_ICA[1]+round(aumento_dim*(col_ICA[1]-col_ICA[0])))) \n","\n","# definiamo le dimensioni della ROI\n","ROI_HEIGHT_ICA = row_ICA[1]-row_ICA[0]+1 # 100\n","ROI_WIDTH_ICA = col_ICA[1]-col_ICA[0]+1 # 126\n","print(f'ROI ICA estratta dal Training set\\nrighe:{row_ICA}\\ncolonne:{col_ICA}')"]},{"cell_type":"markdown","metadata":{"id":"XSXrgC6DSsXu"},"source":["Verifica della dimensione della ROI ICA sul Validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeLy9PW5StC7"},"outputs":[],"source":["# cerchiamo una ROI nelle immagini, identificata come il minimo rettangolo \n","# contenente tutte le segmentazioni manuali delle immagini del Training set\n","Y_sum = np.sum(Y_val_ICA[:,:,:,1]+Y_val_ICA[:,:,:,2],axis = 0)\n","Y_sum[Y_sum>0] = 1\n","fig = px.imshow(Y_sum)\n","fig.show()\n","\n","limits = np.where(Y_sum>0)\n","row_v = [limits[0].min(),limits[0].max()]\n","col_v = [limits[1].min(),limits[1].max()]\n","print(f'ROI estratta dal Validation set\\nrighe:{row_v}\\ncolonne:{col_v}')\n","\n","if col_v[0]< col_ICA[0] or col_v[1]>col_ICA[1]:\n","  print('Attenzione! Controllare le dimensioni della ROI ICA (Val > Train)')\n","else:\n","  print('ROI OK')"]},{"cell_type":"markdown","metadata":{"id":"cOWfMZgxmETI"},"source":["Estrazione della ROI - ECA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atPolS5_mETI"},"outputs":[],"source":["# cerchiamo una ROI nelle immagini, identificata come il minimo rettangolo \n","# contenente tutte le segmentazioni manuali delle immagini del Training set\n","Y_sum = np.sum(Y_train_ECA[:,:,:,1]+Y_train_ECA[:,:,:,2],axis = 0)\n","Y_sum[Y_sum>0] = 1\n","fig = px.imshow(Y_sum)\n","fig.show()\n","\n","limits = np.where(Y_sum>0)\n","row_ECA = [limits[0].min(),limits[0].max()]\n","col_ECA = [limits[1].min(),limits[1].max()]\n","\n","# Per essere sicuri di comprendere anche tutti i casi del Test e Validation set,\n","# aumentiamo le dimensioni della ROI ottenuta del 15% per lato\n","aumento_dim = 0.1\n","row_ECA[0] = int(min(abs(row_ECA[0]-round(aumento_dim*(row_ECA[1]-row_ECA[0]))),0))\n","row_ECA[1] = int(min(IMG_HEIGHT-1, row_ECA[1]+round(aumento_dim*(row_ECA[1]-row_ECA[0]))))\n","\n","col_ECA[0] = col_ECA[0] - round(aumento_dim*(col_ECA[1]-col_ECA[0]))\n","col_ECA[1] = int(min(IMG_WIDTH/2-1, col_ECA[1]+round(aumento_dim*(col_ECA[1]-col_ECA[0]))))\n","\n","# definiamo le dimensioni della ROI\n","ROI_HEIGHT_ECA = row_ECA[1]-row_ECA[0]+1 # 98\n","ROI_WIDTH_ECA = col_ECA[1]-col_ECA[0]+1 # 112\n","print(f'ROI ECA estratta dal Training set\\nrighe:{row_ECA}\\ncolonne:{col_ICA}')"]},{"cell_type":"markdown","metadata":{"id":"4SJDP4yLmETJ"},"source":["Verifica della dimensione della ROI ECA sul Validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34jxnGuhmETJ"},"outputs":[],"source":["# cerchiamo una ROI nelle immagini, identificata come il minimo rettangolo \n","# contenente tutte le segmentazioni manuali delle immagini del Training set\n","Y_sum = np.sum(Y_val_ECA[:,:,:,1]+Y_val_ECA[:,:,:,2],axis = 0)\n","Y_sum[Y_sum>0] = 1\n","fig = px.imshow(Y_sum)\n","fig.show()\n","\n","limits = np.where(Y_sum>0)\n","row_v = [limits[0].min(),limits[0].max()]\n","col_v = [limits[1].min(),limits[1].max()]\n","print(f'ROI estratta dal Validation set\\nrighe:{row_v}\\ncolonne:{col_v}')\n","\n","if col_v[0]< col_ECA[0] or col_v[1]>col_ECA[1]:\n","  print('Attenzione! Controllare le dimensioni della ROI ECA (Val > Train)')\n","else:\n","  print('ROI OK')"]},{"cell_type":"markdown","metadata":{"id":"4f8CuA8WMduF"},"source":["Creazione di sottomatrici X e Y contenenti solamente le ROI delle immagini e delle maschere"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c0XlcXvMeOn"},"outputs":[],"source":["# Training set\n","X_train_ICA = X_train_ICA[:,row_ICA[0]:row_ICA[1]+1,col_ICA[0]:col_ICA[1]+1]\n","Y_train_ICA = Y_train_ICA[:,row_ICA[0]:row_ICA[1]+1,col_ICA[0]:col_ICA[1]+1,:]\n","X_train_ECA = X_train_ECA[:,row_ECA[0]:row_ECA[1]+1,col_ECA[0]:col_ECA[1]+1]\n","Y_train_ECA = Y_train_ECA[:,row_ECA[0]:row_ECA[1]+1,col_ECA[0]:col_ECA[1]+1,:]\n","\n","# Validation set\n","X_val_ICA = X_val_ICA[:,row_ICA[0]:row_ICA[1]+1,col_ICA[0]:col_ICA[1]+1]\n","Y_val_ICA = Y_val_ICA[:,row_ICA[0]:row_ICA[1]+1,col_ICA[0]:col_ICA[1]+1,:]\n","X_val_ECA = X_val_ECA[:,row_ECA[0]:row_ECA[1]+1,col_ECA[0]:col_ECA[1]+1]\n","Y_val_ECA = Y_val_ECA[:,row_ECA[0]:row_ECA[1]+1,col_ECA[0]:col_ECA[1]+1,:]"]},{"cell_type":"markdown","metadata":{"id":"rggjEcdYZxRu"},"source":["Verifica di corretta creazione delle matrici"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5Blw2XXXeWB"},"outputs":[],"source":["# numero di slice da visualizzare\n","n_slices = 30\n","\n","# Training Set\n","index = random.randint(0,n_images_train_ICA-(n_slices+1))\n","\n","Y_vis = np.zeros_like(Y_train_ICA[index:index+n_slices])\n","for n_slice in range(n_slices):\n","  Y_vis[n_slice] = mark_boundaries(X_train_ICA[index+n_slice],Y_train_ICA[index+n_slice,:,:,1].astype(np.uint8))\n","\n","fig = px.imshow(Y_vis, animation_frame=0, binary_string=True, labels=dict(animation_frame=\"slice\"))\n","fig.show()\n","\n","# Validation Set\n","index = random.randint(0,n_images_val_ICA-(n_slices+1))\n","\n","Y_vis = np.zeros_like(Y_val_ICA[index:index+n_slices])\n","for n_slice in range(n_slices):\n","  Y_vis[n_slice] = mark_boundaries(X_val_ICA[index+n_slice],Y_val_ICA[index+n_slice,:,:,1].astype(np.uint8))\n","\n","fig = px.imshow(Y_vis, animation_frame=0, binary_string=True, labels=dict(animation_frame=\"slice\"))\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"MhHYLz09-7JC"},"source":["Preparazione delle matrici per la rete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8WXpebF-uX2"},"outputs":[],"source":["# Passiamo da dimensioni (x,x,x) a dimensioni (x,x,x,1) come richiesto dalla rete\n","X_train_ICA = np.expand_dims(X_train_ICA, axis=3)\n","X_val_ICA = np.expand_dims(X_val_ICA, axis=3)\n","\n","X_train_ECA = np.expand_dims(X_train_ECA, axis=3)\n","X_val_ECA = np.expand_dims(X_val_ECA, axis=3)\n","\n","# diamo in input alla rete delle immagini quadrate di dimensioni multiple di 32 \n","# -> troviamo il minimo multiplo di 32 superiore alla maggiore larghezza attuale\n","# NOTA: impostiamo la stessa dimensione per le immagini delle carotidi ICA ed\n","# ECA da fornire alla rete poiché alleniamo la rete ECA partendo dai pesi della\n","# rete ICA\n","bigger_width = max(ROI_WIDTH_ECA,ROI_WIDTH_ICA)\n","NET_IMG_WIDTH = -((-bigger_width) // 32) * 32 # 160\n","NET_IMG_HEIGHT = -((-bigger_width) // 32) * 32 # 160\n","# input_shape: shape of input data/image ``(H, W, C)``, in general case you do \n","# not need to set ``H`` and ``W`` shapes, just pass ``(None, None, C)`` to make \n","# your model be able to process images af any size, but ``H`` and ``W`` of input\n","# images should be divisible by factor ``32``\n","\n","# Zero padding delle immagini fino alla dimensione (NET_IMG_HEIGHT,NET_IMG_WIDTH)\n","X_train_ICA = tf.image.pad_to_bounding_box(X_train_ICA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","Y_train_ICA = tf.image.pad_to_bounding_box(Y_train_ICA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","X_val_ICA = tf.image.pad_to_bounding_box(X_val_ICA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","Y_val_ICA = tf.image.pad_to_bounding_box(Y_val_ICA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","\n","X_train_ECA = tf.image.pad_to_bounding_box(X_train_ECA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","Y_train_ECA = tf.image.pad_to_bounding_box(Y_train_ECA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","X_val_ECA = tf.image.pad_to_bounding_box(X_val_ECA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()\n","Y_val_ECA = tf.image.pad_to_bounding_box(Y_val_ECA, 0, 0, NET_IMG_HEIGHT, NET_IMG_WIDTH).numpy()"]},{"cell_type":"markdown","metadata":{"id":"-MbcMwqK2yVQ"},"source":["Salvataggio delle matrici create e delle informazioni sulle ROI e sulle immagini da fornire alla rete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYjsPPxm2yVY"},"outputs":[],"source":["# ICA\n","with open(os.path.join(PICKLE_ICA_path,'train_ROI_biforcazioni.pickle'), 'wb') as f:\n","    pickle.dump([X_train_ICA,Y_train_ICA,names_train_ICA,X_bif_train_ICA,Y_bif_train_ICA], f)\n","\n","with open(os.path.join(PICKLE_ICA_path,'validation_ROI_biforcazioni.pickle'), 'wb') as f:\n","    pickle.dump([X_val_ICA,Y_val_ICA,names_val_ICA,X_bif_val_ICA,Y_bif_val_ICA], f)\n","\n","with open(os.path.join(PICKLE_ICA_path,'ROI_NET_informations.pickle'), 'wb') as f:\n","    pickle.dump([row_ICA,col_ICA,ROI_HEIGHT_ICA,ROI_WIDTH_ICA,NET_IMG_HEIGHT,NET_IMG_WIDTH], f)\n","\n","# ECA\n","with open(os.path.join(PICKLE_ECA_path,'train_ROI_biforcazioni.pickle'), 'wb') as f:\n","    pickle.dump([X_train_ECA,Y_train_ECA,names_train_ECA,X_bif_train_ECA,Y_bif_train_ECA], f)\n","\n","with open(os.path.join(PICKLE_ECA_path,'validation_ROI_biforcazioni.pickle'), 'wb') as f:\n","    pickle.dump([X_val_ECA,Y_val_ECA,names_val_ECA,X_bif_val_ECA,Y_bif_val_ECA], f)\n","\n","with open(os.path.join(PICKLE_ECA_path,'ROI_NET_informations.pickle'), 'wb') as f:\n","    pickle.dump([row_ECA,col_ECA,ROI_HEIGHT_ECA,ROI_WIDTH_ECA,NET_IMG_HEIGHT,NET_IMG_WIDTH], f)"]},{"cell_type":"markdown","metadata":{"id":"HhUx3-0jyOT0"},"source":["Determinazione delle aree da utilizzare in postprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEya-P5cyOKu"},"outputs":[],"source":["# Lumen\n","sum_lumi = [np.sum(Y_train_ICA[i,:,:,2]) for i in range(Y_train_ICA.shape[0])]\n","sum_lumi_ECA = [np.sum(Y_train_ECA[i,:,:,2]) for i in range(Y_train_ECA.shape[0])]\n","\n","sum_lumi.extend(sum_lumi_ECA) \n","sum_lumi = np.asarray(sum_lumi)\n","\n","# plot istogrammi\n","fig = plt.figure(figsize=(15,6))\n","fig.suptitle('Istogrammi Aree - Training Set', fontsize=16)\n","\n","ax1 = plt.subplot(2, 2, 1)\n","plt.hist(sum_lumi,bins=100)\n","plt.title('Lumen')\n","\n","ax2 = plt.subplot(2, 2, 2)\n","plt.hist(sum_lumi[sum_lumi<100],bins=100) \n","plt.title('Zoom: Lumen < 100')\n","\n","# Wall\n","sum_wall = [np.sum(Y_train_ICA[i,:,:,1]+Y_train_ICA[i,:,:,2]) for i in range(Y_train_ICA.shape[0])]\n","sum_wall_ECA = [np.sum(Y_train_ECA[i,:,:,1]+Y_train_ECA[i,:,:,2]) for i in range(Y_train_ECA.shape[0])]\n","\n","sum_wall.extend(sum_lumi_ECA) \n","sum_wall = np.asarray(sum_wall)\n","\n","# plot istogrammi\n","ax3 = plt.subplot(2, 2, 3) \n","plt.hist(sum_wall,bins=100) \n","plt.title('Wall')\n","\n","ax4 = plt.subplot(2, 2, 4)\n","plt.hist(sum_wall[sum_wall<200],bins=100)\n","plt.title('Zoom: Wall < 200')\n","\n","# Escludendo le aree pari a 0 (maschere nere) e poche eccezioni, per i lumi \n","# identifichiamo minima area pari a circa 40, mentre per i wall pari a circa 75.\n","# -> scegliamo quindi le soglie di area per eliminare i piccoli oggetti in post \n","# processing (skimage - remove_small_objects) \n","# -> per riempire i piccoli buchi (skimage - remove_small_holes) invece, \n","# scegliamo soglia pari a 10 sia per lumen che per wall\n","\n","# inserimento delle soglie scelte nell'immagine\n","soglia_holes = 10\n","soglia_obj_wall = 75\n","soglia_obj_lumen = 40\n","\n","ax1.axvline(soglia_obj_lumen, color='red', linewidth=1, linestyle='--')\n","ax2.axvline(soglia_obj_lumen, color='red', linewidth=1, linestyle='--')\n","\n","ax3.axvline(soglia_obj_wall, color='red', linewidth=1, linestyle='--')\n","ax4.axvline(soglia_obj_wall, color='red', linewidth=1, linestyle='--')\n","\n","fig.tight_layout() #tight margins\n","plt.show()\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"B_Preprocessing.ipynb","provenance":[],"history_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}