{"cells":[{"cell_type":"markdown","metadata":{"id":"hBbrypRRpiHn"},"source":["# **Elaborazione di Immagini Mediche**\n","## Vessel Wall Segmentation Challenge - A.A. 2021/22 \n","\n","### Script di Testing\n","\n","Rigazio Sofia, Roccaro Lucia, Romano Anastasio, Ruzzante Elena"]},{"cell_type":"markdown","metadata":{"id":"vBzvaDj3Io8B"},"source":["Collegamento a Google Drive e installazione delle librerie necessarie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZD1JvhVfQnI"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install tensorflow==2.1.0\n","!pip install keras==2.3.1\n","!pip install h5py==2.10.0 \n","!pip install plotly==5.3.1\n","!pip install pydicom"]},{"cell_type":"markdown","metadata":{"id":"j0DGsHkaI3jT"},"source":["Importazione delle librerie necessarie\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpJAl9SpUB8D"},"outputs":[],"source":["import os\n","import numpy as np\n","import plotly.express as px\n","import pickle\n","import json\n","import math\n","import pydicom\n","import glob\n","\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","from skimage.io import imread, imsave\n","from skimage.transform import resize\n","from skimage.segmentation import mark_boundaries\n","\n","from keras.models import load_model\n","from keras.utils.np_utils import to_categorical\n","\n","from skimage import morphology\n","from skimage.measure import regionprops\n","import tensorflow as tf\n","from skimage.io import imsave"]},{"cell_type":"markdown","metadata":{"id":"xe8q2nilVO0g"},"source":["Definizione dei path e settaggio dei parametri"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8qZACUQAsjm"},"outputs":[],"source":["current_dir = '/content/drive/MyDrive/Colab Notebooks/EIM/VesselWallSegmentationChallenge'\n","dataset_name = '3D_dataset'\n","n_subjects = 50\n","\n","carotid_types = ['ICA','ECA']\n","arts = ['ICAL','ECAL','ICAR','ECAR']\n","\n","# Path\n","TRAIN_path = os.path.join(current_dir,dataset_name,'TRAIN')\n","VAL_path = os.path.join(current_dir,dataset_name,'VALIDATION')\n","TEST_path = os.path.join(current_dir,'DATASET','TEST')\n","RESULTS_path = os.path.join(current_dir,'RESULTS')\n","JSON_path = os.path.join(current_dir,'PICKLE_and_JSON')\n","PICKLE_ICA_path = os.path.join(JSON_path,'ICA')\n","PICKLE_ECA_path = os.path.join(JSON_path,'ICA')\n","\n","# Cartelle\n","train_folders_ICA = []\n","train_folders_ECA = []\n","val_folders_ICA = []\n","val_folders_ECA = []\n","for arti in arts:\n","  # Training set\n","  for casei in os.listdir(TRAIN_path):\n","    cpath = os.path.join(TRAIN_path, casei, arti)\n","    if arti[0:3] == carotid_types[0]: # ICA\n","      train_folders_ICA.append(cpath)\n","    else: # ECA\n","      train_folders_ECA.append(cpath)\n","\n","  # Validation set\n","  for casei in os.listdir(VAL_path):\n","    cpath = os.path.join(VAL_path, casei, arti)\n","    if arti[0:3] == carotid_types[0]: # ICA\n","      val_folders_ICA.append(cpath)\n","    else: # ECA\n","      val_folders_ECA.append(cpath)\n","# Test set\n","test_folders = [os.path.join(TEST_path,os.listdir(TEST_path)[i]) for i in range(len(os.listdir(TEST_path)))]\n","\n","# Load dei dizionari contenenti le informazioni sulle immagini\n","with open(os.path.join(JSON_path,'labels_TRAIN.json'),\"r\") as f:\n","  labels_TRAIN = json.load(f)\n","  f.close\n","with open(os.path.join(JSON_path,'labels_VAL.json'),\"r\") as f:\n","  labels_VAL = json.load(f)\n","  f.close\n","with open(os.path.join(JSON_path,'labels_TEST.json'),\"r\") as f:\n","  labels_TEST = json.load(f)\n","  f.close\n","\n","# Definizione dei parametri\n","chosen = val_folders_ICA[0].split('/')[-2] # estraiamo il nome del primo soggetto\n","typical_shape = labels_VAL[chosen]['original_shape']\n","IMG_WIDTH = typical_shape[1] # la larghezza sono le colonne -> 720\n","IMG_HEIGHT = typical_shape[0] # l'altezza sono le righe -> 100\n","NUM_CLASSES = 3 # vogliamo segmentare tre classi per ogni rete: lume, wall e background\n","IMG_CHANNELS = 1 # Le immagini fornite sono grayscale\n","# il numero di slice è variabile -> non lo definiamo\n","\n","# Creazione delle cartelle che conterranno i risultati della segmentazione automatica\n","try:\n","  os.mkdir(RESULTS_path)\n","except:\n","  pass\n","\n","for subject in range(1,n_subjects+1):\n","  if subject == 16:\n","    pass # abbiamo eliminato il soggetto 16 dal dataset\n","  else:\n","    name = '0_P'+str(subject)+'_U'\n","    try:\n","      os.mkdir(os.path.join(RESULTS_path,name))\n","    except:\n","      pass"]},{"cell_type":"markdown","metadata":{"id":"My1SHS8BW_ti"},"source":["## Creazione delle maschere automatiche"]},{"cell_type":"markdown","metadata":{"id":"UpDvGM4NV4bh"},"source":["Load delle informazioni sulle ROI e sulle immagini da fornire alla rete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2Wab2WZV4LG"},"outputs":[],"source":["with open(os.path.join(PICKLE_ICA_path,'ROI_NET_informations.pickle'), 'rb') as f:\n","  row_ICA,col_ICA,ROI_HEIGHT_ICA,ROI_WIDTH_ICA,NET_IMG_HEIGHT,NET_IMG_WIDTH = pickle.load(f)\n","\n","with open(os.path.join(PICKLE_ECA_path,'ROI_NET_informations.pickle'), 'rb') as f:\n","  row_ECA,col_ECA,ROI_HEIGHT_ECA,ROI_WIDTH_ECA,NET_IMG_HEIGHT,NET_IMG_WIDTH = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"t-RrngYHt6dM"},"source":["Load dei modelli allenati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUCANQ08t9RJ"},"outputs":[],"source":["net_name = 'trained_net_ICA.h5'\n","model_path = os.path.join(current_dir, 'Trained_Nets', net_name)\n","model_ICA = load_model(model_path)\n","\n","net_name = 'trained_net_ECA.h5'\n","model_path = os.path.join(current_dir, 'Trained_Nets', net_name)\n","model_ECA = load_model(model_path)"]},{"cell_type":"markdown","metadata":{"id":"F8Z5hXgkJltB"},"source":["Funzione che effettua l'eliminazione automatica delle biforcazioni"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkAGZov_4rfc"},"outputs":[],"source":["def rimozione_biforcazioni(image,wall_mask,lumen_mask):\n","  \n","  # lumen\n","  properties = regionprops(lumen_mask.astype(np.uint8), cache=False)\n","  # se le maschere sono nere, la funzione regionprops non calcola le proprietà\n","  if len(properties): \n","    if properties[0].major_axis_length == 0:\n","      # se ci sono maschere con lume composto da un solo punto (l'asse \n","      # maggiore in questo caso ha lunghezza pari a 0) si tratta di errori \n","      # nelle segmentazioni manuali: impostiamo quindi le roundness pari a 0 e\n","      # l'area maggiore della soglia in modo da eliminare le maschere\n","      roundness_lumen = 0\n","      roundness_wall = 0\n","      area_lumen = soglia_area_lumen + 1\n","    else:\n","      area_lumen = lumen_mask.sum()\n","      roundness_lumen = 4*area_lumen/(math.pi*properties[0].major_axis_length**2)\n","      # wall\n","      area_wall = wall_mask.sum()\n","      properties = regionprops(wall_mask.astype(np.uint8), cache=False)\n","      roundness_wall = 4*area_wall/(math.pi*properties[0].major_axis_length**2)\n","  else:\n","    # se le maschere sono nere (quelle introdotte per il training della rete), \n","    # impostiamo dei valori delle proprietà in modo che le slice non vengano \n","    # eliminate\n","    roundness_lumen = 1\n","    roundness_wall = 1\n","    area_lumen = 0\n","\n","  # rimozione della slice:\n","  # effettuiamo il controllo sia su wall che su lumen. se solo wall o solo \n","  # lumen ha forma allungata, allora non ci troviamo in corrispondenza di una \n","  # biforcazione. la forma non circolare potrebbe essere docuta ad esempio \n","  # alla presenza di una placca\n","  if roundness_wall < soglia_wall and roundness_lumen < soglia_lumen and area_lumen > soglia_area_lumen:\n","    image = None\n","\n","  return image"]},{"cell_type":"markdown","metadata":{"id":"KLqIvHAyg9Yu"},"source":["Funzione che effettua il preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2haSUvLqz4U"},"outputs":[],"source":["def preprocess(image,wall_mask,lumen_mask,side,row,col):\n","\n","  # flip left-right se la carotide si trova sul lato sinistro (a destra nell'immagine)\n","  if side == 'L':\n","    image = np.fliplr(image)\n","    if wall_mask is not None:\n","      wall_mask = np.fliplr(wall_mask)\n","      lumen_mask = np.fliplr(lumen_mask)\n","\n","  # consideriamo solo la metà sinistra dell'immagine (che contiene ICAL/ECAL flippate o ICAR/ECAR)\n","  half_width = int(image.shape[1]/2)\n","  image = image[:,0:half_width]\n","  if wall_mask is not None:\n","    wall_mask = wall_mask[:,0:half_width]\n","    lumen_mask = lumen_mask[:,0:half_width]\n","\n","  # controllo sulle dimensioni delle immagini\n","  if image.shape != (IMG_HEIGHT,int(IMG_WIDTH/2)): #(100,360)\n","    # effettuiamo un resize with pad per mantenere l'aspect ratio delle immagini \n","    # e delle maschere\n","    image = np.expand_dims(image,axis = 2)\n","    image = np.squeeze(tf.image.resize_with_pad(image,IMG_HEIGHT,int(IMG_WIDTH/2), antialias=True).numpy())\n","    \n","    # Spostiamo le colonne aggiunte con lo zero padding a sinistra dell'immagine\n","    # con lo zero padding vengono inserite 80 colonne nere per lato\n","    to_shift = 80\n","    image = np.roll(image, to_shift, axis = 1)\n","     \n","    if wall_mask is not None: # resize delle maschere in Training e Validation Set\n","      # Conversione della maschera in dato categorico\n","      mask = to_categorical(wall_mask+lumen_mask, num_classes=NUM_CLASSES, dtype='float32')\n","      mask = tf.image.resize_with_pad(mask,IMG_HEIGHT,int(IMG_WIDTH/2), antialias=True).numpy() \n","        # reimpostiamo i valori dei pixel coinvolti nel resize a 0 e 1: i pixel ai \n","      # bordi delle segmentazioni potrebbero essersi sfumati\n","      soglia = 0.5\n","      mask[mask < soglia] = 0.0\n","      mask[mask >= soglia] = 1.0\n","      \n","      mask = np.roll(mask, to_shift, axis = 1)\n","      wall_mask = mask[:,:,1]\n","      lumen_mask = mask[:,:,2]\n","  # rimozione delle biforcazioni in Training e Validation Set\n","  if wall_mask is not None:\n","    image = rimozione_biforcazioni(image,wall_mask,lumen_mask)\n","   \n","  if image is not None: # se la slice non è stata rimossa (biforcazione)\n","    # estrazione della ROI\n","    image = image[row[0]:row[1]+1,col[0]:col[1]+1]\n","    # preparazione dell'immagine per la rete\n","    image = np.expand_dims(image, axis = [0,3]) # da dimensione (x,x) a (1,x,x,1)\n","    image = tf.image.pad_to_bounding_box(image,0,0,NET_IMG_HEIGHT,NET_IMG_WIDTH).numpy() # .numpy() perché dopo lo zero-padding img_slice è diventata un tensore -> serve riconvertirla in array!\n","\n","  return image"]},{"cell_type":"markdown","metadata":{"id":"y8n2_kXR8sin"},"source":["Funzione che effettua il post processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00V7Haz78sUT"},"outputs":[],"source":["def postprocess(wall_mask,lumen_mask,side,original_shape,to_shift,row,col,ROI_HEIGHT,ROI_WIDTH):\n","\n","  # rimozione del bordo nero aggiunto con zero-padding durante il preprocessing\n","  wall_mask_ROI = wall_mask[0:ROI_HEIGHT,0:ROI_WIDTH]\n","  lumen_mask_ROI = lumen_mask[0:ROI_HEIGHT,0:ROI_WIDTH]\n","\n","  if original_shape != [IMG_HEIGHT,IMG_WIDTH]:\n","    # riposizionamento della maschera alle giuste coordinate rispetto alla metà \n","    # sinistra dell'immagine\n","    wall_mask_half = np.zeros((IMG_HEIGHT,int(IMG_WIDTH/2)), dtype = np.float32) # 100 360\n","    lumen_mask_half = np.zeros((IMG_HEIGHT,int(IMG_WIDTH/2)), dtype = np.float32)\n","    # posizioniamo la maschera alle giuste coordinate\n","    wall_mask_half[row[0]:row[1]+1,col[0]:col[1]+1] = wall_mask_ROI\n","    lumen_mask_half[row[0]:row[1]+1,col[0]:col[1]+1] = lumen_mask_ROI\n","    # rimozione delle colonne nere (zero padding) aggiunte durante il resize in \n","    # fase di preprocessing per mantenere l'aspect ratio\n","    black_cols = 80\n","    wall_mask_half = wall_mask_half[:,black_cols*2+1:]\n","    lumen_mask_half = lumen_mask_half[:,black_cols*2+1:]\n","    # effettuiamo il resize per riportare la mezza immagine alle sue dimensioni\n","    # originali (160*320)\n","    wall_mask_half = resize(wall_mask_half,(original_shape[0],int(original_shape[1]/2)), preserve_range = True, anti_aliasing = True)\n","    lumen_mask_half = resize(lumen_mask_half,(original_shape[0],int(original_shape[1]/2)), preserve_range = True, anti_aliasing = True)\n","\n","    # riposizionamento della maschera alle giuste coordinate rispetto all'immagine intera \n","    wall_mask = np.zeros((original_shape[0],original_shape[1]), dtype = np.float32) # 160 640\n","    lumen_mask = np.zeros((original_shape[0],original_shape[1]), dtype = np.float32)\n","    wall_mask[:,0:int(original_shape[1]/2)] = wall_mask_half\n","    lumen_mask[:,0:int(original_shape[1]/2)] = lumen_mask_half\n","    \n","    # reimpostiamo i valori dei pixel coinvolti nel resize a 0 e 1: i pixel ai \n","    # bordi delle segmentazioni potrebbero essersi sfumati\n","    soglia = 0.5\n","    lumen_mask[lumen_mask < soglia] = 0\n","    lumen_mask[lumen_mask >= soglia] = 1\n","    wall_mask[wall_mask < soglia] = 0\n","    wall_mask[wall_mask >= soglia] = 1\n","  else:\n","    # riposizionamento della maschera alle giuste coordinate rispetto all'immagine intera\n","    wall_mask = np.zeros((IMG_HEIGHT,IMG_WIDTH), dtype = np.float32)\n","    lumen_mask = np.zeros((IMG_HEIGHT,IMG_WIDTH), dtype = np.float32)\n","    # posizioniamo la maschera nel lato sinistro dell'immagine\n","    wall_mask[row[0]:row[1]+1,col[0]:col[1]+1] = wall_mask_ROI\n","    lumen_mask[row[0]:row[1]+1,col[0]:col[1]+1] = lumen_mask_ROI\n","  \n","  if side == 'L':\n","    # se la maschera è del lato sinistro (destra nell'immagine originale) la \n","    # flippiamo left-right\n","    wall_mask = np.fliplr(wall_mask)\n","    lumen_mask = np.fliplr(lumen_mask)\n","\n","  # Rimozione di piccoli oggetti e piccoli buchi. Le soglie sono state \n","  # identificate mediante l'osservazione della minima area di wall e lumen delle\n","  # al termine dello script C\n","  soglia_holes = 10\n","  soglia_obj_wall = 75\n","  soglia_obj_lumen = 40\n","  wall_mask = morphology.remove_small_holes(wall_mask.astype(bool), area_threshold=soglia_holes)\n","  wall_mask = morphology.remove_small_objects(wall_mask, min_size=soglia_obj_wall).astype(np.float32)\n","  lumen_mask = morphology.remove_small_holes(lumen_mask.astype(bool), area_threshold=soglia_holes)\n","  lumen_mask = morphology.remove_small_objects(lumen_mask, min_size=soglia_obj_lumen).astype(np.float32)\n","  \n","  # Shift sulle colonne delle maschere nella giusta posizione (operazione \n","  # inversa a quella fatta nello script A_ReadCASCADEcontours per centrare il \n","  # collo del soggetto nell'immagine)\n","  # NOTA: qui axis=1 perché in questo caso le maschere sono delle singole slice,\n","  # nello script A invece era axis=2 perché lavoravamo con volumi 3D\n","  wall_mask = np.roll(wall_mask, -to_shift, axis=1)\n","  lumen_mask = np.roll(lumen_mask, -to_shift, axis=1)\n","  \n","  return wall_mask, lumen_mask"]},{"cell_type":"markdown","metadata":{"id":"aTRRHrfShLdL"},"source":["Funzione per leggere i file DICOM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AOomg6jhLOP"},"outputs":[],"source":["def readDicom(path):\n","  pi = os.path.basename(path).split('_')[1]\n","  dcm_size = len(glob.glob(path+'/*.dcm'))\n","  dcms = []\n","  dicom_slicei = 0\n","  for n_slicei in range(1,dcm_size+1):\n","    dicom_slicei = dicom_slicei+1\n","    path_dicom = path+'/E'+pi+'S101I%d.dcm'%dicom_slicei\n","    while os.path.exists(path_dicom) == False:\n","      dicom_slicei = dicom_slicei+1\n","      path_dicom = path+'/E'+pi+'S101I%d.dcm'%dicom_slicei\n","    dcms.append(path_dicom)\n","\n","  dcm_f = pydicom.read_file(dcms[0]).pixel_array\n","  dcm_size = max(dcm_f.shape)\n","\n","  cdcm1 = pydicom.read_file(dcms[0]).pixel_array\n","\n","  cdcm_img = np.zeros((len(dcms),cdcm1.shape[0],cdcm1.shape[1]),dtype=np.uint8)\n","  for dcmi in range(len(dcms)):\n","    cdcm_img[dcmi,:,:] = pydicom.read_file(dcms[dcmi]).pixel_array\n","\n","  # nomi delle immagini\n","  original_names = [dcms[i].split('/')[-1] for i in range(len(dcms))]\n","  original_names = [original_names[i].split('.')[0] for i in range(len(original_names))]\n","\n","  return cdcm_img, original_names"]},{"cell_type":"markdown","metadata":{"id":"xsEVKvj3p009"},"source":["Creazione delle maschere automatiche"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psMlSFjoS4TE"},"outputs":[],"source":["def net_prediction(list_folders,set_,labels,arti,model,row,col,ROI_HEIGHT,ROI_WIDTH):\n","  for folder in tqdm(list_folders,total = len(list_folders)):\n","    \n","    if os.path.exists(folder) == True:\n","      if set_ == 'TEST':\n","        \n","        v_subj = folder.split('/')[-1] # ID soggetto\n","        # load dei dati\n","        image, original_name = readDicom(folder)\n","        \n","        # shift dell'immagine lungo le colonne\n","        to_shift = labels[v_subj]['shift']\n","        image = np.roll(image, to_shift, axis=2)\n","        \n","      else: \n","        # load dei dati\n","        image = imread(os.path.join(folder,'image.tiff'))\n","        # carichiamo anche le maschere per eliminare le slice con biforcazioni \n","        wall_mask = imread(os.path.join(folder,'wall_mask.tiff'))\n","        lumen_mask = imread(os.path.join(folder,'lumen_mask.tiff'))\n","        v_subj = folder.split('/')[-2] # ID soggetto\n","        arti = folder.split('/')[-1] # ICAL, ICAR, ECAL, ECAR\n","        # lista di nomi dei file originali\n","        original_name = labels[v_subj][arti]['name']\n","\n","\n","      # dimensione delle immagini originali\n","      original_shape = labels[v_subj]['original_shape']\n","      \n","      # consideriamo le slice separatamente\n","      slice_counter = 0 # contatore del numero effettivo di slice (escludendo le biforcazioni)\n","      for i in range(image.shape[0]):\n","        img_slice = image[i]\n","        \n","        # preprocessing\n","        if set_ == 'TEST':\n","          img_slice = preprocess(img_slice,None,None,arti[-1],row,col)\n","        else:\n","          img_slice = preprocess(img_slice,wall_mask[i],lumen_mask[i],arti[-1],row,col)\n","        # se la slice non è stata eliminata nel preprocessing procediamo \n","        if img_slice is not None: \n","          \n","          slice_counter = slice_counter+1 # incrementiamo il contatore delle slice effettive\n","          # predizione della maschera tramite la rete\n","          softmax = model.predict(img_slice)\n","          softmax = np.squeeze(softmax) # rimuoviamo la prima e la quarta dimensione (pari a 1)\n","          \n","          pred_lumen_mask = softmax[:,:,2] # 2 è solo lume\n","          pred_wall_mask = softmax[:,:,1] + softmax[:,:,2] # 1 è solo parete senza lume\n","\n","          # scegliamo soglia pari a 0.5 in modo da massimizzare la distanza tra i valori attesi (0 e 1)\n","          soglia = 0.5\n","          pred_lumen_mask[pred_lumen_mask < soglia] = 0\n","          pred_lumen_mask[pred_lumen_mask >= soglia] = 1\n","          pred_wall_mask[pred_wall_mask < soglia] = 0\n","          pred_wall_mask[pred_wall_mask >= soglia] = 1\n","\n","          # post processing\n","          pred_wall_mask,pred_lumen_mask = postprocess(pred_wall_mask,pred_lumen_mask,arti[-1],original_shape,labels[v_subj]['shift'],row,col,ROI_HEIGHT,ROI_WIDTH)\n","          \n","          # salvataggio delle maschere automatiche: effettuiamo un controllo in \n","          # quanto le maschere nere non devono essere salvate\n","          name = original_name[slice_counter-1] + '_' + arti\n","          if pred_wall_mask.sum() > 0 and pred_lumen_mask.sum() > 0:\n","            imsave(os.path.join(RESULTS_path,v_subj,name+'_wall.png'), 255*pred_wall_mask.astype(np.uint8),check_contrast=False)   \n","            imsave(os.path.join(RESULTS_path,v_subj,name+'_lume.png'), 255*pred_lumen_mask.astype(np.uint8),check_contrast=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGe1I-AHTXXF"},"outputs":[],"source":["# soglie per la rimozione delle biforcazioni (individuate nello script B)\n","soglia_wall = 0.7\n","soglia_lumen = 0.65\n","soglia_area_lumen = 245\n","\n","for carotid_type in carotid_types:\n","\n","  row = eval(f'row_{carotid_type}')\n","  col = eval(f'col_{carotid_type}')\n","  ROI_HEIGHT = eval(f'ROI_HEIGHT_{carotid_type}')\n","  ROI_WIDTH = eval(f'ROI_WIDTH_{carotid_type}')\n","\n","  print(f'Net prediction - {carotid_type}')\n","  # Training Set\n","  #print('Training set')\n","  #net_prediction(eval(f'train_folders_{carotid_type}'), 'TRAIN', labels_TRAIN, None,eval(f'model_{carotid_type}'),row,col,ROI_HEIGHT,ROI_WIDTH)\n","\n","  # Validaion Set\n","  #print('Validation set')\n","  #net_prediction(eval(f'val_folders_{carotid_type}'), 'VALIDATION', labels_VAL, None,eval(f'model_{carotid_type}'),row,col,ROI_HEIGHT,ROI_WIDTH)\n","\n","  # Test Set\n","  print('Test set - Left side')\n","  net_prediction(test_folders, 'TEST', labels_TEST, carotid_type+'L',eval(f'model_{carotid_type}'),row,col,ROI_HEIGHT,ROI_WIDTH)\n","  print('Test set - Right side')\n","  net_prediction(test_folders, 'TEST', labels_TEST, carotid_type+'R',eval(f'model_{carotid_type}'),row,col,ROI_HEIGHT,ROI_WIDTH)\n","  print()"]},{"cell_type":"markdown","metadata":{"id":"qtIBpZRKWuk6"},"source":["## Valutazione delle performance"]},{"cell_type":"markdown","metadata":{"id":"tWB60wecXkJW"},"source":["Funzione per il calcolo del coefficiente di Dice Similarity (DSC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKBJOHGNIr0K"},"outputs":[],"source":["def calculate_DSC(Y_manual, Y_auto):\n","  n_images = Y_manual.shape[0]\n","  DSC = np.zeros(n_images, dtype = np.float64)\n","  \n","  for i in range(n_images):\n","    x = Y_manual[i] # manual mask\n","    y = Y_auto[i] # automatic mask\n","\n","    x_int_y = np.logical_and(x,y)\n","    \n","    num = 2.*x_int_y.sum()\n","    den = x.sum()+y.sum()\n","    \n","    # se entrambe le maschere sono nere \n","    if num == 0 and den == 0: \n","      DSC[i] = np.nan # da rimuovere in seguito\n","    else:\n","    # Coefficiente di Dice Similarity\n","      DSC[i] = num/den\n","\n","  # eliminiamo i NaN dal vettore\n","  DSC = DSC[~np.isnan(DSC)] \n","\n","  return DSC"]},{"cell_type":"markdown","metadata":{"id":"YV1vKjV2HVip"},"source":["Funzione per il calcolo della Relative Volume Difference (RVD)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cNiu3IwmHVZj"},"outputs":[],"source":["def calculate_RVD(Y_manual, Y_auto):\n","  \n","  # inizializzazione dei contatori\n","  n_correct_black_mask = 0 # contatore per le maschere che devono essere nere e sono nere\n","  n_black_where_segmented = 0 # contatore per le maschere che devono segmentare e invece sono nere\n","  n_segmented_where_black = 0 # contatore per le maschere che devono essere nere e invece c'è segmentazione\n","  \n","  n_images = Y_manual.shape[0]\n","  RVD = np.zeros(n_images, dtype = np.float64)\n","  \n","  for i in range(n_images):\n","    x = Y_manual[i] # manual mask\n","    y = Y_auto[i] # automatic mask\n","\n","    # Relative volume difference\n","    num = y.sum()-x.sum()\n","    den = x.sum()\n","    # se le maschere sono uguali e sono entrambe nere\n","    if den == 0 and num == 0: \n","      RVD[i] = np.nan  \n","      n_correct_black_mask += 1 # maschere che devono essere nera e sono nere\n","    # se vi sono delle segmentazioni \"in eccesso\" nelle maschere auto rispetto alle manuali, che invece sono nere\n","    elif den == 0 and num > 0:   \n","      RVD[i] = np.nan\n","      n_segmented_where_black += 1 # maschere che devono essere nere e invece c'è segmentazione\n","    elif y.sum() == 0 and num != 0: # in questo caso avremo RVD minore di zero. \n","      RVD[i] = num/den # -1\n","      n_black_where_segmented += 1 # maschera è nera e invece doveva segmentare\n","    else:\n","      # Relative Volume Difference\n","      RVD[i] = num/den\n","\n","  # creiamo un vettore contenente i contatori per le maschere nere\n","  black_counter = [n_correct_black_mask, n_segmented_where_black, n_black_where_segmented] \n","  # eliminiamo i NaN dal vettore\n","  RVD = RVD[~np.isnan(RVD)] \n","\n","  return RVD, black_counter"]},{"cell_type":"markdown","metadata":{"id":"lqSriCAke1dz"},"source":["Funzione per la visualizzazione dei grafici delle metriche di valutazione"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hu90xn8ne1Ot"},"outputs":[],"source":["def show_metrics(DSC, RVD_wall, RVD_lumen, black_counter_wall, black_counter_lumen, set_, side):\n","  \n","  # Grafici\n","  fig = plt.figure(figsize=(15, 5))\n","  fig.suptitle(f'{set_} set - {side} side')\n","  ax1 = plt.subplot(1, 3, 1)\n","  ax1.scatter(range(1,DSC.shape[0]+1),DSC)\n","  ax1.set_title('DSC')\n","\n","  ax2 = plt.subplot(1, 3, 2)\n","  ax2.scatter(range(1,RVD_wall.shape[0]+1),RVD_wall)\n","  ax2.set_title('RVD wall')\n","\n","  ax3 = plt.subplot(1, 3, 3)\n","  ax3.scatter(range(1,RVD_lumen.shape[0]+1),RVD_lumen)\n","  ax3.set_title('RVD lumen')\n","  fig.show()\n","\n","  # Valori medi\n","  print(f'{set_} set - {side} side:')\n","  print(\"\\tDSC (media ± std) = {:.4f} ± {:.4f}\".format(np.mean(DSC),np.std(DSC))) \n","  print(\"\\tRVD del wall (media ± std) = {:.4f} ± {:.4f}\".format(np.mean(RVD_wall),np.std(RVD_wall)))\n","  print(\"\\tRVD del lume (media ± std) = {:.4f} ± {:.4f}\".format(np.mean(RVD_lumen),np.std(RVD_lumen)))\n","  # Contatori maschere nere\n","  print(f'Numero di maschere correttamente nere:\\n\\t wall = {black_counter_wall[0]}\\n\\t lumen = {black_counter_lumen[0]}')\n","  print(f'Numero di maschere erroneamente nere:\\n\\t wall = {black_counter_wall[1]}\\n\\t lumen = {black_counter_lumen[1]}')\n","  print(f'Numero di maschere erroneamente segmentate:\\n\\t wall = {black_counter_wall[2]}\\n\\t lumen = {black_counter_lumen[2]}\\n')\n","  "]},{"cell_type":"markdown","metadata":{"id":"sSxdhUtGp8ft"},"source":["Calcolo delle metriche e visualizzazione dei risultati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urV9pIE4LOj9"},"outputs":[],"source":["def performance_evaluation(labels, set_path, side, subject_to_visualize):\n","  if side == 'L':\n","    arts = ['ICAL','ECAL']\n","  elif side == 'R':\n","    arts = ['ICAR','ECAR']\n","\n","  # Inizializzazioni\n","  DSC = []\n","  RVD_wall = []\n","  RVD_lumen = []\n","  black_counter_wall = np.array([0,0,0])\n","  black_counter_lumen = np.array([0,0,0])\n","  \n","  for v_subj in tqdm(list(labels.keys()), total = len(list(labels.keys()))):\n","\n","    # dimensioni originali delle slice del soggetto\n","    original_shape = labels[v_subj]['original_shape']\n","    # cartella che contiene le segmentazioni automatiche del soggetto\n","    results_folder = os.path.join(RESULTS_path,v_subj)\n","\n","    # estrazione dal dizionario del parametro per lo shift\n","    to_shift = labels[v_subj]['shift']\n","\n","    for arti in arts:\n","      \n","      # numero di slice che abbiamo utilizzato per l'allenamento della rete\n","      # -> quelle su cui calcolare le metriche di valutazione\n","      slice_number = len(labels[v_subj][arti]['number'])\n","\n","      # inizializzazione delle matrici\n","      X = np.zeros((slice_number,original_shape[0],original_shape[1]),dtype = np.uint8)\n","      Y = np.zeros((slice_number,original_shape[0],original_shape[1],2),dtype = np.float32)\n","      Y_auto = np.zeros((slice_number,original_shape[0],original_shape[1],2),dtype = np.float32)\n","\n","      # load del volume e delle maschere manuali\n","      path = os.path.join(set_path, v_subj, arti)\n","      if os.path.exists(path):\n","        image = imread(os.path.join(path, 'image.tiff'))\n","        wall_mask = imread(os.path.join(path, 'wall_mask.tiff'))\n","        lumen_mask = imread(os.path.join(path, 'lumen_mask.tiff'))\n","        \n","        # nomi di tutte le slice contenute in 'image'\n","        slice_list_original = labels[v_subj][arti+'_original']['name']\n","        # nomi delle slice che abbiamo utilizzato per l'allenamento della rete\n","        # -> quelle su cui calcolare le metriche di valutazione\n","        slice_list = labels[v_subj][arti]['name']\n","        \n","        for i, slice_name in enumerate(slice_list):\n","          # troviamo l'indice in slice_list_original (il numero di slice in image)\n","          index = slice_list_original.index(slice_name)\n","          # inseriamo la slice e le maschere manuali nelle matrici\n","          X[i] = image[index]\n","          Y[i,:,:,0] = wall_mask[index]\n","          Y[i,:,:,1] = lumen_mask[index]\n","          # load delle maschere automatiche\n","          # proviamo il caricamento delle maschere automatiche. se non sono presenti \n","          # significa che la maschere sono nere e quindi non sono state salvate\n","          try:\n","            Y_auto[i,:,:,0] = imread(os.path.join(results_folder, slice_name+'_'+arti+'_wall.png')).astype(np.float32)/255.0\n","            Y_auto[i,:,:,1] = imread(os.path.join(results_folder, slice_name+'_'+arti+'_lume.png')).astype(np.float32)/255.0\n","          except:\n","            Y_auto[i,:,:,0] = np.zeros((original_shape[0],original_shape[1]),dtype = np.float32)\n","            Y_auto[i,:,:,1] = np.zeros((original_shape[0],original_shape[1]),dtype = np.float32)  \n","\n","        # prima di calcolare le metriche di valutazione delle performance, \n","        # shiftiamo le immagini e le maschere manuali in modo da riportarle alla\n","        # loro posizione originale (sono salvate in .tiff nella cartella \n","        # 3D_dataset già shiftate -> script A)\n","        X = np.roll(X, -to_shift, axis=2)\n","        Y = np.roll(Y, -to_shift, axis=2)\n","        # NOTA: non è necessario shiftare anche Y_auto in quanto le maschere \n","        # automatiche sono salvate nella cartella RESULTS in .png in posizione \n","        # corrispondente alla posizione originale delle slice DICOM\n","\n","        # calcoliamo le metriche di valutazione\n","        DSC = np.append(DSC,calculate_DSC(Y[:,:,:,0]-Y[:,:,:,1], Y_auto[:,:,:,0]-Y_auto[:,:,:,1]))\n","        # Wall\n","        RVD, black_counter = calculate_RVD(Y[:,:,:,0], Y_auto[:,:,:,0])\n","        RVD_wall = np.append(RVD_wall,RVD)\n","        black_counter_wall = black_counter_wall + black_counter\n","        # Lumen\n","        RVD, black_counter = calculate_RVD(Y[:,:,:,1], Y_auto[:,:,:,1])\n","        RVD_lumen = np.append(RVD_lumen, RVD)\n","        black_counter_lumen = black_counter_lumen + black_counter\n","\n","        # se il nome del soggetto corrisponde a subject_to_visualize, \n","        # visualizzazione dei risultati\n","        if v_subj == subject_to_visualize:\n","          Y_vis = np.zeros((slice_number,original_shape[0],original_shape[1],3),dtype = np.float32)\n","          for n_slice in range(slice_number):\n","            mask = Y[n_slice,:,:,0]-Y[n_slice,:,:,1]\n","            mask_auto = Y_auto[n_slice,:,:,0]-Y_auto[n_slice,:,:,1]\n","            Y_vis[n_slice] = mark_boundaries(mark_boundaries(X[n_slice].astype(np.float32),mask.astype(np.uint8),color=[0,255,0]),mask_auto.astype(np.uint8),color=[255,0,0])\n","\n","          fig = px.imshow(Y_vis, animation_frame=0, binary_string=True, labels=dict(animation_frame=\"slice\"))\n","          for i, frame in enumerate(fig.frames):\n","            frame.layout.title = f'Soggetto: {v_subj} - Carotide: {arti} - Nome slice: {slice_list[i]}'\n","          fig.show()\n","     \n","  return DSC, RVD_wall, RVD_lumen, black_counter_wall, black_counter_lumen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFvDMrIr9XJG"},"outputs":[],"source":["# inserire l'ID di un soggetto appartenente al Validation set (ad es '0_P19_U')\n","# per visualizzarne i risultati\n","subject_to_visualize = None \n","\n","# Validation Set\n","print(f'Evaluating performances: Validation set')\n","print('\\nLeft side')\n","DSC_L_val, RVD_wall_L_val, RVD_lumen_L_val, black_counter_wall_L_val, black_counter_lumen_L_val = performance_evaluation(labels_VAL,VAL_path,'L',subject_to_visualize)\n","print('Right side')\n","DSC_R_val, RVD_wall_R_val, RVD_lumen_R_val, black_counter_wall_R_val, black_counter_lumen_R_val = performance_evaluation(labels_VAL,VAL_path,'R',subject_to_visualize)\n","print()\n","\n","# Left side\n","show_metrics(DSC_L_val, RVD_wall_L_val, RVD_lumen_L_val, black_counter_wall_L_val, black_counter_lumen_L_val,'Validation','Left')\n","# Right side\n","show_metrics(DSC_R_val, RVD_wall_R_val, RVD_lumen_R_val, black_counter_wall_R_val, black_counter_lumen_R_val,'Validation','Right')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecfZabvQg-xh"},"outputs":[],"source":["# inserire l'ID di un soggetto appartenente al Training set (ad es '0_P34_U')\n","# per visualizzarne i risultati\n","subject_to_visualize = None \n","\n","# Training Set\n","print(f'Evaluating performances: Training set')\n","print('\\nLeft side')\n","DSC_L_train, RVD_wall_L_train, RVD_lumen_L_train, black_counter_wall_L_train, black_counter_lumen_L_train = performance_evaluation(labels_TRAIN,TRAIN_path,'L',subject_to_visualize)\n","print('Right side')\n","DSC_R_train, RVD_wall_R_train, RVD_lumen_R_train, black_counter_wall_R_train, black_counter_lumen_R_train = performance_evaluation(labels_TRAIN,TRAIN_path,'R',subject_to_visualize)\n","print()\n","\n","# Left side\n","show_metrics(DSC_L_train, RVD_wall_L_train, RVD_lumen_L_train, black_counter_wall_L_train, black_counter_lumen_L_train, 'Training','Left')\n","# Right side\n","show_metrics(DSC_R_train, RVD_wall_R_train, RVD_lumen_R_train, black_counter_wall_R_train, black_counter_lumen_R_train, 'Training','Right')"]},{"cell_type":"markdown","metadata":{"id":"-MbcMwqK2yVQ"},"source":["Salvataggio dei coefficienti calcolati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYjsPPxm2yVY"},"outputs":[],"source":["with open(os.path.join(JSON_path,'DSC_RVD_train.pickle'), 'wb') as f:\n","    pickle.dump([DSC_L_train, RVD_wall_L_train, RVD_lumen_L_train,DSC_R_train, RVD_wall_R_train, RVD_lumen_R_train], f)\n","\n","with open(os.path.join(JSON_path,'DSC_RVD_validation.pickle'), 'wb') as f:\n","    pickle.dump([DSC_L_val, RVD_wall_L_val, RVD_lumen_L_val,DSC_R_val, RVD_wall_R_val, RVD_lumen_R_val], f)"]},{"cell_type":"markdown","metadata":{"id":"OWo67oA32yVY"},"source":["Load dei coefficienti calcolati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DiOKftl2yVY"},"outputs":[],"source":["with open(os.path.join(JSON_path,'DSC_RVD_train.pickle'), 'rb') as f:\n","  DSC_L_train, RVD_wall_L_train, RVD_lumen_L_train,DSC_R_train, RVD_wall_R_train, RVD_lumen_R_train = pickle.load(f)\n","\n","with open(os.path.join(JSON_path,'DSC_RVD_validation.pickle'), 'rb') as f:\n","  DSC_L_val, RVD_wall_L_val, RVD_lumen_L_val,DSC_R_val, RVD_wall_R_val, RVD_lumen_R_val = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"Jw7dRlpEoUbJ"},"source":["Box plot delle metriche"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSXlpYVJoUKw"},"outputs":[],"source":["fig = plt.figure(figsize=(15, 5))\n","fig.suptitle('Carotidi interne (ICA) ed esterne (ECA)')\n","ax1 = plt.subplot(1, 3, 1)\n","ax1.boxplot(np.array([DSC_L_val,DSC_R_val,DSC_L_train,DSC_R_train],dtype = \"object\"), showfliers=False)\n","plt.xticks([1, 2, 3, 4], ['Val L', 'Val R', 'Train L', 'Train R'])\n","ax1.set_title('DSC')\n","\n","ax2 = plt.subplot(1, 3, 2)\n","ax2.boxplot(np.array([RVD_wall_L_val,RVD_wall_R_val,RVD_wall_L_train,RVD_wall_R_train],dtype = \"object\"), showfliers=False)\n","plt.xticks([1, 2, 3, 4], ['Val L', 'Val R', 'Train L', 'Train R'])\n","ax2.set_title('RVD wall')\n","\n","ax3 = plt.subplot(1, 3, 3)\n","ax3.boxplot(np.array([RVD_lumen_L_val,RVD_lumen_R_val,RVD_lumen_L_train,RVD_lumen_R_train],dtype = \"object\"), showfliers=False)\n","plt.xticks([1, 2, 3, 4], ['Val L', 'Val R', 'Train L', 'Train R'])\n","ax3.set_title('RVD lumen')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"ez3h394xrKpW"},"source":["Visualizzazione dei risultati su un soggetto appartenente al Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5S7E3Y1CrKgv"},"outputs":[],"source":["# inserire l'ID di un soggetto appartenente al Test set (ad es '0_P43_U') per\n","# visualizzarne i risultati\n","v_subj = list(labels_TEST.keys())[0]\n","\n","# dimensioni originali delle slice del soggetto\n","original_shape = labels_TEST[v_subj]['original_shape']\n","# cartella che contiene le segmentazioni automatiche del soggetto\n","results_folder = os.path.join(RESULTS_path,v_subj)\n","\n","# load del volume\n","image, slice_list = readDicom(os.path.join(TEST_path,v_subj))\n","\n","# Visualizziamo i risultati di una slice ogni 10 per il Test set\n","kept_slices = range(0,image.shape[0]-1,10)\n","image = image[kept_slices]\n","slice_list = [slice_list[i] for i in kept_slices]\n","\n","# numero di slice disponibili\n","slice_number = image.shape[0]\n","\n","for arti in arts:\n","\n","  # inizializzazione della matrice che conterrà le maschere automatiche\n","  Y_auto = np.zeros((slice_number,original_shape[0],original_shape[1],2),dtype = np.uint8)\n","\n","  for i, slice_name in enumerate(slice_list):\n","    # load delle maschere automatiche\n","    # proviamo il caricamento delle maschere automatiche. se non sono presenti \n","    # significa che la maschere sono nere e quindi non sono state salvate\n","    try:\n","      Y_auto[i,:,:,0] = imread(os.path.join(results_folder, slice_name+'_'+arti+'_wall.png'))\n","      Y_auto[i,:,:,1] = imread(os.path.join(results_folder, slice_name+'_'+arti+'_lume.png'))\n","    except:  \n","      Y_auto[i,:,:,0] = np.zeros((original_shape[0],original_shape[1]),dtype = np.uint8)  \n","      Y_auto[i,:,:,1] = np.zeros((original_shape[0],original_shape[1]),dtype = np.uint8)\n","      \n","  # visualizzazione dei risultati\n","  Y_vis = np.zeros((slice_number,original_shape[0],original_shape[1],3),dtype = np.float32)\n","  for n_slice in range(slice_number):\n","    mask_auto = Y_auto[n_slice,:,:,0]-Y_auto[n_slice,:,:,1]\n","    Y_vis[n_slice] = mark_boundaries(image[n_slice].astype(np.float32),mask_auto.astype(np.uint8),color=[255,0,0])\n","\n","  fig = px.imshow(Y_vis, animation_frame=0, binary_string=True, labels=dict(animation_frame=\"slice\"))\n","  for i, frame in enumerate(fig.frames):\n","    frame.layout.title = f'Soggetto: {v_subj} - Carotide: {arti} - Nome slice: {slice_list[i]}'\n","  fig.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"D_Testing.ipynb","provenance":[],"history_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}